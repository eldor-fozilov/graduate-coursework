{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "reference: https://github.com/Spijkervet/SimCLR"
      ],
      "metadata": {
        "id": "2Qb4qyyUfVsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import dependency"
      ],
      "metadata": {
        "id": "351st3x8on5C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYS8GNRSbZky"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "!pip install wandb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define device and label names for CIFAR10"
      ],
      "metadata": {
        "id": "y_8Ukvjboquh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "i85-igaPf-bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1: Pre-training"
      ],
      "metadata": {
        "id": "YpT8jTnd0xmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define transforms for training and testing"
      ],
      "metadata": {
        "id": "EN6ODvS8otnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformsSimCLR:\n",
        "    def __init__(self, size):\n",
        "        s = 0.5\n",
        "        color_jitter = torchvision.transforms.ColorJitter(\n",
        "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
        "        )\n",
        "        self.train_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.RandomResizedCrop(size=size, scale=(0.5, 1)),\n",
        "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
        "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
        "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "        self.test_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize(size=size),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.train_transform(x), self.train_transform(x)"
      ],
      "metadata": {
        "id": "S2NsDiESesH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define dataset and loader"
      ],
      "metadata": {
        "id": "O9mXpM7Jowjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = './dataset'\n",
        "img_size = 32\n",
        "simclr_dataset = torchvision.datasets.CIFAR10(\n",
        "    dataset_dir,\n",
        "    download=True,\n",
        "    transform=TransformsSimCLR(size=img_size)\n",
        ")"
      ],
      "metadata": {
        "id": "StMxQyN0f6S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "simclr_dataloader = DataLoader(simclr_dataset, batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "Jm7U-oAEhqDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the example"
      ],
      "metadata": {
        "id": "IZuNVvTsozG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(simclr_dataloader))\n",
        "img_1 = sample[0][0]\n",
        "img_2 = sample[0][1]\n",
        "label = sample[1]"
      ],
      "metadata": {
        "id": "zlAa8HBshzd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.randint(low=0, high=batch_size, size=(1,)).item()\n",
        "fig, ax = plt.subplots(1, 2, figsize=(3, 3))\n",
        "ax[0].imshow(img_1[idx].permute(1, 2, 0))\n",
        "ax[1].imshow(img_2[idx].permute(1, 2, 0))\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "ax[1].set_xticks([])\n",
        "ax[1].set_yticks([])\n",
        "fig.suptitle('label: {}'.format(label_names[label[idx]]))"
      ],
      "metadata": {
        "id": "x37hVtVFi3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchvision.models.resnet18()"
      ],
      "metadata": {
        "id": "JoGW5BcOmt4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define SimCLR model"
      ],
      "metadata": {
        "id": "-65VHlQjo1St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = torchvision.models.resnet18()\n",
        "        self.n_features = self.encoder.fc.in_features\n",
        "        self.encoder.fc = nn.Identity()\n",
        "\n",
        "        self.projection_layer = nn.Sequential(nn.Linear(self.n_features, self.n_features),\n",
        "                                              nn.GELU(),\n",
        "                                              nn.Linear(self.n_features, self.n_features))\n",
        "\n",
        "    def encode(self, x1, x2):\n",
        "        return self.encoder(x1), self.encoder(x2)\n",
        "\n",
        "    def project(self, h1, h2):\n",
        "        return self.projection_layer(h1), self.projection_layer(h2)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        h1, h2 = self.encode(x1, x2)\n",
        "        z1, z2 = self.project(h1, h2)\n",
        "        return h1, h2, z1, z2"
      ],
      "metadata": {
        "id": "7GWBLxNfj4EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simclr_model = SimCLR().to(device)\n",
        "simclr_optimizer = torch.optim.Adam(simclr_model.parameters(), lr=0.0003, weight_decay=1e-6)"
      ],
      "metadata": {
        "id": "FsZWABXTmUI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B = 4\n",
        "D = 10\n",
        "z1 = torch.randn(B, D)\n",
        "z2 = torch.randn(B, D)\n",
        "\n",
        "nz_1 = F.normalize(z1, dim=1)\n",
        "nz_2 = F.normalize(z2, dim=1)\n",
        "similarity_matrix = torch.matmul(nz_1, nz_2.T)\n",
        "\n",
        "pos_mask = torch.eye(B, dtype=torch.bool)\n",
        "positives = similarity_matrix[pos_mask].view(B, -1)\n",
        "negatives = similarity_matrix[~pos_mask].view(B, -1)\n",
        "print(positives.shape, negatives.shape)"
      ],
      "metadata": {
        "id": "_0P8SfnzpaRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define loss function"
      ],
      "metadata": {
        "id": "NbyHp64Lo3Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def info_nce_loss(z1, z2, temperature=0.5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    nz_1 = F.normalize(z1, dim=1)\n",
        "    nz_2 = F.normalize(z2, dim=1)\n",
        "    similarity_matrix = torch.matmul(nz_1, nz_2.T)\n",
        "\n",
        "    pos_mask = torch.eye(batch_size, dtype=torch.bool).to(device)\n",
        "    positives = similarity_matrix[pos_mask].view(batch_size, -1)\n",
        "    negatives = similarity_matrix[~pos_mask].view(batch_size, -1)\n",
        "\n",
        "    logits = torch.cat([positives, negatives], dim=1)\n",
        "    labels = torch.zeros(batch_size, dtype=torch.long).to(device)\n",
        "\n",
        "    logits = logits / temperature\n",
        "\n",
        "    loss = criterion(logits, labels)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "4ndl6i5ct1ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define simclr training function"
      ],
      "metadata": {
        "id": "yQS5pZ7bo5pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simclr_train(simclr_model, simclr_optimizer, sample):\n",
        "    img_1 = sample[0][0].to(device)\n",
        "    img_2 = sample[0][1].to(device)\n",
        "\n",
        "    h1, h2, z1, z2 = simclr_model(img_1, img_2)\n",
        "\n",
        "    loss = info_nce_loss(z1, z2)\n",
        "\n",
        "    simclr_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    simclr_optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "lhrdH0lAuGc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train the simclr model"
      ],
      "metadata": {
        "id": "gnbEjcU4o8Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 5\n",
        "wandb.init(project='simclr', entity='cotton-ahn')\n",
        "for e in range(epoch):\n",
        "    total_loss = 0.0\n",
        "    for sample in tqdm(simclr_dataloader):\n",
        "        loss = simclr_train(simclr_model, simclr_optimizer, sample)\n",
        "        total_loss += loss / len(simclr_dataloader)\n",
        "        wandb.log({'loss': loss})\n",
        "    print('[EPOCH {}] loss : {:.03f}'.format(e+1, total_loss))\n",
        "    torch.save(simclr_model.state_dict(), './checkpoint.pth')"
      ],
      "metadata": {
        "id": "twOLh2RRwKct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2: Supervised learning"
      ],
      "metadata": {
        "id": "tqh80X1UprZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define datasets and loaders"
      ],
      "metadata": {
        "id": "cTPelz83ptL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    dataset_dir,\n",
        "    download=True,\n",
        "    transform=TransformsSimCLR(size=img_size).test_transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    dataset_dir,\n",
        "    download=True,\n",
        "    train = False,\n",
        "    transform=TransformsSimCLR(size=img_size).test_transform\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "qCagtPdN3jrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define MLP based classifier which uses feature extractor of SimCLR"
      ],
      "metadata": {
        "id": "QHLXBC5Ipvkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_Classifier(nn.Module):\n",
        "    def __init__(self, simclr_model, feat_dim=512, n_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.simclr_model = simclr_model\n",
        "        self.feat_dim = feat_dim\n",
        "\n",
        "        for p in self.simclr_model.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        self.mlp = nn.Sequential(nn.Linear(feat_dim, feat_dim),\n",
        "                                 nn.GELU(),\n",
        "                                 nn.Linear(feat_dim, n_classes))\n",
        "\n",
        "    def forward(self, img):\n",
        "        B = img.shape[0]\n",
        "\n",
        "        self.simclr_model.eval()\n",
        "        with torch.no_grad():\n",
        "            feature = self.simclr_model.encoder(img)\n",
        "        return self.mlp(feature.reshape(B, -1))"
      ],
      "metadata": {
        "id": "q15wWxbjwegQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simclr_model = SimCLR().to(device)\n",
        "simclr_model.load_state_dict(torch.load('./checkpoint_ver1.pth'))\n",
        "supervise_model = MLP_Classifier(simclr_model).to(device)\n",
        "supervise_optimizer = torch.optim.Adam(supervise_model.parameters(), lr=0.0003, weight_decay=1e-6)"
      ],
      "metadata": {
        "id": "-rOyBOYs4_CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervise_train(model, optimizer, sample):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    img = sample[0].to(device)\n",
        "    label = sample[1].to(device)\n",
        "\n",
        "    logit = model(img)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(logit, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    n_correct = sum(torch.argmax(logit, dim=1) == label).item()\n",
        "\n",
        "    return loss.item(), n_correct"
      ],
      "metadata": {
        "id": "HXUli5J1w-1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, sample):\n",
        "    model.eval()\n",
        "    img = sample[0].to(device)\n",
        "    label = sample[1].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logit = model(img)\n",
        "    n_correct = sum(torch.argmax(logit, dim=1) == label).item()\n",
        "\n",
        "    return n_correct"
      ],
      "metadata": {
        "id": "P9Cyxt5L8tw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "for e in range(epoch):\n",
        "    total_loss = 0.0\n",
        "    for sample in tqdm(train_dataloader):\n",
        "        loss, n_correct = supervise_train(supervise_model, supervise_optimizer, sample)\n",
        "        total_loss += loss / len(train_dataloader)\n",
        "\n",
        "    total_n_correct = 0.0\n",
        "    for sample in tqdm(test_dataloader):\n",
        "        n_correct = test(supervise_model, sample)\n",
        "        total_n_correct += n_correct / len(test_dataset)\n",
        "\n",
        "    print('[EPOCH {}] loss: {}, n_correct: {}%'.format(e+1, total_loss, total_n_correct*100))"
      ],
      "metadata": {
        "id": "azbXDPXQ5h20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_correct"
      ],
      "metadata": {
        "id": "6j7BjUbi5yPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8F6j0rgE56cL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}